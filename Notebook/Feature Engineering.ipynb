{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "pd.pandas.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162980, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../data/Twitter_Data.csv\")\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>Things that had to be done while Cleaning the Data for Sentimental analysis</span>\n",
    "<ul>\n",
    "<li>Make text lowercase</li>\n",
    "<li>Remove punctuation</li>\n",
    "<li>Remove emoji’s</li>\n",
    "<li>Remove stopwords</li>\n",
    "<li>Lemmatization</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reffer this Link for Understanding.\n",
    "https://towardsdatascience.com/cleaning-preprocessing-text-data-for-sentiment-analysis-382a41f150d6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Text to Lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['clean_text'] = train_data['clean_text'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['clean_text'] = train_data['clean_text'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "\n",
    "### Removing the Stop Words \n",
    "stop = stopwords.words('english')\n",
    "train_data['clean_text'] = train_data['clean_text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatisation (or lemmatization) in linguistics is the process of grouping together the inflected forms of a word so they can be analysed as a single item, identified by the word's lemma, or dictionary form\n",
    "\n",
    "Lemmatization removes the grammar tense and transforms each word into its original form. Another way of converting words to its original form is called stemming.<br>\n",
    " While stemming takes the linguistic root of a word, lemmatization is taking a word into its original lemma. For example, if we performed stemming on the word “apples”, the result would be “appl”, whereas lemmatization would give us “apple”. Therefore I prefer lemmatization over stemming, as its much easier to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melwin you need to learn about the spacy and parser and all\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "def space(comment):\n",
    "    doc = nlp(comment)\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "train_data['clean_text'] = train_data['clean_text'].apply(space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## implement BAG OF WORDS\n",
    "tfidfvector=TfidfVectorizer(ngram_range=(2,2))\n",
    "train_data['clean_processed_text']=tfidfvector.fit_transform(train_data['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modi promise minimum government maximum govern...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(0, 692567)\\t0.2462726699429557\\n  (0, 28956...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk nonsense continue drama vote modi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0, 692567)\\t0.2462726699429557\\n  (0, 28956...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>say vote modi welcome bjp tell rahul main camp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0, 692567)\\t0.2462726699429557\\n  (0, 28956...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ask supporter prefix chowkidar name modi great...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0, 692567)\\t0.2462726699429557\\n  (0, 28956...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer among powerful world leader today trump...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0, 692567)\\t0.2462726699429557\\n  (0, 28956...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category  \\\n",
       "0  modi promise minimum government maximum govern...      -1.0   \n",
       "1             talk nonsense continue drama vote modi       0.0   \n",
       "2  say vote modi welcome bjp tell rahul main camp...       1.0   \n",
       "3  ask supporter prefix chowkidar name modi great...       1.0   \n",
       "4  answer among powerful world leader today trump...       1.0   \n",
       "\n",
       "                                clean_processed_text  \n",
       "0    (0, 692567)\\t0.2462726699429557\\n  (0, 28956...  \n",
       "1    (0, 692567)\\t0.2462726699429557\\n  (0, 28956...  \n",
       "2    (0, 692567)\\t0.2462726699429557\\n  (0, 28956...  \n",
       "3    (0, 692567)\\t0.2462726699429557\\n  (0, 28956...  \n",
       "4    (0, 692567)\\t0.2462726699429557\\n  (0, 28956...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('../data/train_processed_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
